分布式服务框架原理与实践阅读笔记



微服务架构

微服务架构带来的改变

应用解耦

分而治之

敏捷交付

微服务架构是一种架构风格，旨在将功能分解到各个离散的服务中实现对解决方案的解耦

基于Docker容器部署微服务，有点高效率和可移植性

当服务治理和运维能力跟不上时，强行推行微服务架构未必是明智之举，技术是为商业服务的，切不可脱离业务实际而使用微服务。

服务化最佳实践

影响RPC性能的主要因素有三个：

1.I/O调用模型：是阻塞IO还是非阻塞IO

2.序列化框架的选择：是文本协议、二进制协议还是压缩二进制协议

3.线程调度模型：是串行调度还是并行调度，是锁机制还是采用无锁化算法



Netty是一个高性能的NIO通信框架

Netty的性能优化措施

- 零拷贝
- 内存池
- 无锁化的串行设计
- 高效的并发编程

Protobuf是一个高性能的序列化框架

影响序列化性能的总结因素如下

1. 序列化之后的码流大小（网络带宽的占用）
2. 序列化反序列化的性能（CPU资源的占用）
3. 是否支持跨语言
4. 并发调用的性能表现

高性能的Reator并发编程模型



Dubbo是阿里开源的分布式框架

研发团队协作问题：共享服务注册中心





#### RPC框架的基本认识

1.RPC是什么？

RPC（Remote Procedure Call，远程方法调用）

核心思想：像调用本地函数那样调用远程函数

2.RPC框架的基本架构

服务端，客户端，注册中心

3.RPC的三个作用

服务寻址，数据编解码，网络传输

4.使用RPC的好处

屏蔽掉本地调用与远程调用的区别；

隐藏掉底层网络通信的复杂性，让我们更加专注于业务逻辑；

5.技术选型

网络IO框架：Java推荐使用Netty,C++推荐使用muduo;

序列化框架：protobuf

服务注册中心：Zookeeper









RPC框架的核心思想就是：**像调用本地函数那样调用远程函数**

RPC就是要像调用本地的函数一样去调远程函数。在研究RPC前，我们先看看本地调用是怎么调的。假设我们要调用[函数Multipl](https://www.zhihu.com/search?q=函数Multipl&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A221638079})y来计算lvalue * rvalue的结果:

```cpp
1 int Multiply(int l, int r) {
2    int y = l * r;
3    return y;
4 }
5 
6 int lvalue = 10;
7 int rvalue = 20;
8 int l_times_r = Multiply(lvalue, rvalue);
```

那么在第8行时，我们实际上执行了以下操作：

1. 将 lvalue 和 rvalue 的值压栈
2. 进入[Multiply函数](https://www.zhihu.com/search?q=Multiply函数&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A221638079})，取出栈中的值10 和 20，将其赋予 l 和 r
3. 执行第2行代码，计算 l * r ，并将结果存在 y
4. 将 y 的值压栈，然后从Multiply返回
5. 第8行，从栈中取出返回值 200 ，并赋值给 l_times_r

以上5步就是执行本地调用的过程。（20190116注：以上步骤只是为了说明原理。事实上编译器经常会做优化，对于参数和返回值少的情况会直接将其存放在寄存器，而不需要压栈弹栈的过程，甚至都不需要调用call，而直接做inline操作。仅就原理来说，这5步是没有问题的。）



**远程过程调用带来的新问题**

在远程调用时，我们需要执行的函数体是在远程的机器上的，也就是说，Multiply是在另一个进程中执行的。这就带来了几个新问题：

1. **Call ID映射**。我们怎么告诉远程机器我们要调用Multiply，而不是Add或者FooBar呢？在本地调用中，函数体是直接通过函数指针来指定的，我们调用Multiply，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。所以，在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 <--> Call ID} 的对应表。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给[服务端](https://www.zhihu.com/search?q=服务端&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A221638079})，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。
2. **序列化和反序列化**。客户端怎么把参数值传给远程的函数呢？在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用C++，客户端用Java或者Python）。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。
3. **网络传输**。远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。Java的Netty也属于这层的东西。

有了这三个机制，就能实现RPC了，具体过程如下：

```cpp
// Client端 
//    int l_times_r = Call(ServerAddr, Multiply, lvalue, rvalue)
1. 将这个调用映射为Call ID。这里假设用最简单的字符串当Call ID的方法
2. 将Call ID，lvalue和rvalue序列化。可以直接将它们的值以二进制形式打包
3. 把2中得到的数据包发送给ServerAddr，这需要使用网络传输层
4. 等待服务器返回结果
5. 如果服务器调用成功，那么就将结果反序列化，并赋给l_times_r

// Server端
1. 在本地维护一个Call ID到函数指针的映射call_id_map，可以用std::map<std::string, std::function<>>
2. 等待请求
3. 得到一个请求后，将其数据包反序列化，得到Call ID
4. 通过在call_id_map中查找，得到相应的函数指针
5. 将lvalue和rvalue反序列化后，在本地调用Multiply函数，得到结果
6. 将结果序列化后通过网络返回给Client
```

所以要实现一个RPC框架，其实只需要按以上流程实现就基本完成了。

其中：

- Call ID映射可以直接使用[函数字符串](https://www.zhihu.com/search?q=函数字符串&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A221638079})，也可以使用整数ID。映射表一般就是一个哈希表。
- 序列化反序列化可以自己写，也可以使用Protobuf或者FlatBuffers之类的。
- 网络传输库可以自己写socket，或者用asio，ZeroMQ，Netty，muduo之类。

当然，这里面还有一些细节可以填充，比如如何处理网络错误，如何防止攻击，如何做流量控制，等等。但有了以上的架构，这些都可以持续加进去。

最后，有兴趣的可以看我们自己写的一个小而精的RPC库 Remmy（[hjk41/Remmy](https://link.zhihu.com/?target=https%3A//github.com/hjk41/Remmy)），对于理解RPC如何工作很有好处。